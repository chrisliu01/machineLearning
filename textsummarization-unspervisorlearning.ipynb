{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Text Summarization Unsupervised Learning</h1>\n",
    "<h3>Author: Chris Gang Liu</h3>\n",
    "<p>\n",
    "1- Background: a summary of available solutions for text summarization. <br />\n",
    "2- Models: Explain how the models work <br />\n",
    "3- Results: Compare two models using the three selected text les and\n",
    "report the results here. <br />\n",
    "4- conclusion: Summarize your paper by a guideline for an enduser so that the enduser can select the best text summarization approach\n",
    "based on your findings.<br />\n",
    "    </p>\n",
    "    \n",
    "#### References\n",
    "\n",
    "Aleksander Kołcz, Features Selection for Text Summuarization: https://www.researchgate.net/profile/Jugal_Kalita/publication/221613265_Summarization_as_Feature_Selection_for_Text_Categorization/links/54b6a2180cf24eb34f6d4c17/Summarization-as-Feature-Selection-for-Text-Categorization.pdf <br>\n",
    "Jaiprakash Verma, Evaulation of unsupervisied Text Summarization: https://www.researchgate.net/publication/317610956_Evaluation_of_Unsupervised_Learning_based_Extractive_Text_Summarization_Technique_for_Large_Scale_Review_and_Feedback_Data<br>\n",
    "Makbule Gulcin Ozsoy, Latent Semantic Analysis approach: https://www.researchgate.net/publication/220195824_Text_summarization_using_Latent_Semantic_Analysis<br>\n",
    "Spacy Frequency Approach: https://github.com/luisfredgs/extractive-text-summarization<br>\n",
    "Mohammad Etemad, Transportation Modes Classification Using Feature Engineering: https://www.researchgate.net/publication/326696576_Transportation_Modes_Classification_Using_Feature_Engineering<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "import distance\n",
    "import string\n",
    "from pprint import pprint\n",
    "import collections, itertools\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.classify.util, nltk.metrics\n",
    "from nltk import cluster\n",
    "from nltk.metrics import *\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.probability import FreqDist, ConditionalFreqDist\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "import statistics\n",
    "import difflib\n",
    "import math\n",
    "from scipy import stats\n",
    "from scipy.stats import mode\n",
    "import IPython\n",
    "import IPython.display\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models Buildup Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from gensim.summarization import summarize\n",
    "from gensim.summarization import keywords\n",
    "from tika import parser # pip install tika\n",
    "from numpy.linalg import svd as singular_value_decomposition\n",
    "from operator import attrgetter\n",
    "from collections import namedtuple\n",
    "import spacy\n",
    "from spacy.lang.pt.stop_words import STOP_WORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import argparse\n",
    "import en_core_web_sm\n",
    "nlp = spacy.load('en')\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models Comparsion Metrics Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reusable funcations\n",
    "##### Bring OOP concepts in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class solutionGuildeline:\n",
    "    def __init__(self):\n",
    "        self.df = pd.DataFrame(columns=['text','abstract','sent_tokens','sent_tokens_counts','word_tokens','word_tokens_counts','normalized_text'\n",
    "                                        ,'gensim_summarizations','latent_semantic_summarization','spacy_extraction_summarization'\n",
    "                                        ,'AI_genims_scores','AI_latent_scores','AI_frequency_scores'])\n",
    "        self.abstracts = []\n",
    "        self.texts = []\n",
    "        self.normalized_texts = []\n",
    "        self.gensim_summarizations = []\n",
    "        self.latent_semantic_summarizations = []\n",
    "        self.spacy_extraction_summarizations = []\n",
    "        self.tokenizedSents = [] # tokenize the whole text sents\n",
    "        self.tokenizedSents_counts = [] #count the whole text sents\n",
    "        self.tokenizedwords = [] # tokenize the whole text words\n",
    "        self.tokenizedwords_counts = []  # count the whole text words  \n",
    "        self.tokenizedAbstractSents = []  # human abstraction sentences \n",
    "        self.tokenizedAbstractSents_counts = [] # human abstraction sentences count\n",
    "        self.tokenizedAbstractwords = [] # human abstraction words\n",
    "        self.tokenizedAbstractwords_counts = [] # # human abstraction words count\n",
    "        self.AI_genims_scores = []\n",
    "        self.AI_latent_scores = []\n",
    "        self.AI_frequency_scores = []\n",
    "        self.Tfidf_scores = []\n",
    "        self.MIN_DIMENSIONS = 3\n",
    "        self.REDUCTION_RATIO = 1/1\n",
    "    \n",
    "    def _dataExtraction(self):\n",
    "        text1_raw = open('StrategiesEducation.txt', 'r').read()\n",
    "        text2_raw = open('Mechoulan_656370.txt', 'r', encoding=\"utf-8\").read()\n",
    "        text3_raw = open('newconstruction.txt', 'r').read()\n",
    "        text1 = text1_raw\n",
    "        self.texts.append(text1)\n",
    "        text2 = text2_raw\n",
    "        self.texts.append(text2)\n",
    "        text3 = text3_raw\n",
    "        self.texts.append(text3)\n",
    "        self.df['text'] = self.texts\n",
    "        return self.df\n",
    "        \n",
    "    def _preprocessData(self):\n",
    "        self.normalized_texts.append(self.normalizeText(self.texts[0]))\n",
    "        self.normalized_texts.append(self.normalizeText(self.texts[1]))\n",
    "        self.normalized_texts.append(self.normalizeText(self.texts[2]))\n",
    "        self.df['normalized_text'] = self.normalized_texts\n",
    "        return self.df\n",
    "    \n",
    "    #unsupervised text summarization needs human made summarization as the reference for evaluating models.\n",
    "    #reference paper: https://www.researchgate.net/publication/317610956_Evaluation_of_Unsupervised_Learning_based_Extractive_Text_Summarization_Technique_for_Large_Scale_Review_and_Feedback_Data    \n",
    "    def _featurePreparation(self):\n",
    "        # add author abastract for evaluation later on\n",
    "        mechoulan_abstract = \"This article examines how the increase in the incarceration of black men and the sex ratio imbalance it induces shape the behavior of young black women. Combining data from the Bureau of Justice Statistics and the Current Population Survey to match male incar- ceration rates with individual observations over two decades, I show that black male incarceration lowers the odds of black non- marital teenage fertility while increasing young black women’s school attainment and early employment. These results can account for the sharp bridging of the racial gap over the 1990s for a range of socioeconomic outcomes among females.\"\n",
    "        StrategiesEducation_abstract  = \"In  2012, analysts estimated  90% of the  world’s data  had come  into existence  within the  previous 2  years (Vesset et al., 2014). Organizations  in all sectors  are struggling with this  volume of data, confident that despite the velocity  at which  it is growing, and the variety  of its formats, there is value. The goal is to  transition  from being data-­--rich to being information-­--rich and knowledge-­--rich, for which  we need  both  data scientists  and people capable of working effectively with data. The McKinsey Global Institute suggested that at current training rates, in the US alone there will be 140,000 - 190,000  more  jobs than trained data scientists by 2018  (Manyika  et al., 2011). On the literacy, fluency, mastery scale, a data scientist would have achieved mastery. However, the same report also estimated a  1,500,000  employee  shortfall of data-savvy analysts  and managers  capable of working with the data to make effective  decisions (Manyika et  al., 2011);  IDC  suggests  a  similar  number  (Vesset  et  al.,  2014).  This latter set of skills is what we refer to as data literacy.\" \\\n",
    "        +\"Across academic disciplines and throughout the private sector, we are recognizing a growing need for data-­--literate graduates from all  backgrounds. The recent Tri-­--Council consultation document on digital scholarship  (Government of Canada, 2013) recognizes this challenge, and  the issue of training in particular: “Digital  data are the raw materials  of the knowledge economy, and are becoming increasingly important for all  areas of society, including industry… The same may be said of the capacity to capture, manage and preserve it, or the requisite training of personnel who can operate effectively  in  this milieu” (Government of Canada, 2013). This recognition prompts the core question addressed in this report:  How  can  post-secondary institutions  in Canada best equip graduates  with the knowledge, understanding, and skills required for the data-­--rich knowledge economy?\" \\\n",
    "        +\"We addressed this question by  examining existing strategies and best practices for teaching data  literacy, synthesizing documented explicit knowledge (from both formal and informal literature) using a narrative-­--synthesis  methodology. When necessary, we  used our team''s expertise  to aid in synthesizing and summarizing; this  expertise spans  multiple disciplines, including Science, Computer Science, Business, Information Management, Arts and Social Sciences, and Education. \"\\\n",
    "        +\"We begin by establishing the skills that comprise data literacy. Data literacy is the ability to collect, manage, evaluate, and apply data, in a critical manner. We define the core skills and competencies that  comprise data literacy, using a thematic analysis of  the elements  of data literacy described in peer-­--reviewed literature. These competencies (23 in  total) and  their skills, knowledge, and expected tasks (64 in total)  are organized under the top-­--level  elements of the definition (data, collect, manage, evaluate, apply) and  are categorized  as conceptual competencies, core competencies, and  advanced  competencies. This view of data literacy is central to our synthesis, which includes  two primary sections: the context  and strategic value of  data literacy education, and best  practices  for  teaching data literacy across disciplines. There also remains much  we do not know, and  further steps that need  to be taken, to understand  data literacy  instructions. \"\n",
    "        newconstruction_abstract = \"The work aims to present the study of the business processes of small building companies. The study led to the development of a basic model of business processes. For this, we applied the multiple case study method as main technique to identify the common processes among the companies studied. The study included five building companies of the city of Curitiba, Paraná, Brazil. Data were collected through semi-structured interviews, document analysis and direct observations in loco. Based on the information obtained, the business process modeling was developed using BPMN notation (Business Process Modeling Notation). Thus, the study allowed the development of a basic model that presents the best practices based on the PCF model (Process Classification Framework), in view of, adequate and compatible with the reality of the organizations that work in the subsector of buildings. The framework obtains a unique view of the processes, presenting the main activities of each business process, with the intention of transmitting a single language within the company.\"\n",
    "        self.abstracts.append(self.normalizeText(StrategiesEducation_abstract))\n",
    "        self.abstracts.append(self.normalizeText(mechoulan_abstract))\n",
    "        self.abstracts.append(self.normalizeText(newconstruction_abstract))\n",
    "        self.df['abstract'] = self.abstracts\n",
    "        self.countTextSents() # count human abstract sent/word count to decide model reduction ratio\n",
    "        self.countHumanAbstractSents() # count human abstract sent/word count to decide model reduction ratio\n",
    "        return self.df\n",
    "        \n",
    "    def _buildingGensimModel(self):\n",
    "        self.gensim_summarizations=[]\n",
    "        text1 = self.df.loc[0]['text']\n",
    "        text2 = self.df.loc[1]['text']\n",
    "        text3 = self.df.loc[2]['text']\n",
    "        genism_summarize1 = summarize(text1, ratio=self.tokenizedAbstractSents_counts[0]/self.tokenizedSents_counts[0]) #api wordcount/ ratio.\n",
    "        print(\"___________________genism summarized text 1:\")\n",
    "        print(genism_summarize1)\n",
    "        self.gensim_summarizations.append(genism_summarize1)\n",
    "        genism_summarize2 = summarize(text2, ratio=self.tokenizedAbstractSents_counts[1]/self.tokenizedSents_counts[1])\n",
    "        print(\"___________________genism summarized text 2:\")\n",
    "        print(genism_summarize2)\n",
    "        self.gensim_summarizations.append(genism_summarize2)\n",
    "        genism_summarize3 = summarize(text3, ratio=self.tokenizedAbstractSents_counts[2]/self.tokenizedSents_counts[2])\n",
    "        print(\"___________________genism summarized text 3:\")\n",
    "        print(genism_summarize3)\n",
    "        self.gensim_summarizations.append(genism_summarize3)\n",
    "        self.df['gensim_summarizations'] = self.gensim_summarizations\n",
    "        return self.df\n",
    "    \n",
    "    def _buildingLatentModel(self):\n",
    "        self.latent_semantic_summarizations = []\n",
    "        text1_normalized = self.df.loc[0]['normalized_text']\n",
    "        text2_normalized = self.df.loc[1]['normalized_text']\n",
    "        text3_normalized = self.df.loc[2]['normalized_text'] \n",
    "        text1_sent_arr = self.df.loc[0]['sent_tokens']\n",
    "        text2_sent_arr = self.df.loc[1]['sent_tokens']\n",
    "        text3_sent_arr = self.df.loc[2]['sent_tokens']\n",
    "        dictionary1 = self.create_dictionary(text1_normalized)\n",
    "        dictionary2 = self.create_dictionary(text2_normalized)\n",
    "        dictionary3 = self.create_dictionary(text3_normalized)\n",
    "        matrix1 = self.create_matrix(text1_sent_arr, dictionary1)\n",
    "        matrix2 = self.create_matrix(text2_sent_arr, dictionary2)\n",
    "        matrix3 = self.create_matrix(text3_sent_arr, dictionary3)\n",
    "        matrix1 = self.compute_term_frequency(matrix1)\n",
    "        matrix2 = self.compute_term_frequency(matrix2)\n",
    "        matrix3 = self.compute_term_frequency(matrix3)\n",
    "        u1, sigma1, v1 = singular_value_decomposition(matrix1, full_matrices=False)\n",
    "        u2, sigma2, v2 = singular_value_decomposition(matrix2, full_matrices=False)\n",
    "        u3, sigma3, v3 = singular_value_decomposition(matrix3, full_matrices=False)\n",
    "        ranks1 = list(self.compute_ranks(sigma1, v1))\n",
    "        ranks2 = list(self.compute_ranks(sigma2, v2))\n",
    "        ranks3 = list(self.compute_ranks(sigma3, v3))\n",
    "        summary1 = self.get_best_sentences(text1_sent_arr, self.tokenizedAbstractSents_counts[0], ranks1)\n",
    "        summary2 = self.get_best_sentences(text2_sent_arr, self.tokenizedAbstractSents_counts[1], ranks2)\n",
    "        summary3 = self.get_best_sentences(text3_sent_arr, self.tokenizedAbstractSents_counts[2], ranks3)\n",
    "        self.latent_semantic_summarizations.append(\" \".join(summary1))\n",
    "        self.latent_semantic_summarizations.append(\" \".join(summary2))\n",
    "        self.latent_semantic_summarizations.append(\" \".join(summary3))\n",
    "        print(\"___________________latent_semantic summarized text 1:\")\n",
    "        print(self.latent_semantic_summarizations[0])\n",
    "        print(\"___________________latent_semantic summarized text 2:\")\n",
    "        print(self.latent_semantic_summarizations[1])\n",
    "        print(\"___________________latent_semantic summarized text 3:\")\n",
    "        print(self.latent_semantic_summarizations[2])\n",
    "        self.df['latent_semantic_summarization'] = self.latent_semantic_summarizations\n",
    "        return self.df\n",
    "\n",
    "    def _buildingSpacyModel(self):\n",
    "        text1_normalized = self.df.loc[0]['normalized_text']\n",
    "        text2_normalized = self.df.loc[1]['normalized_text']\n",
    "        text3_normalized = self.df.loc[2]['normalized_text'] \n",
    "        spacy_summarization1 = self.spacy_summarization(text1_normalized, self.tokenizedAbstractSents_counts[0])\n",
    "        spacy_summarization2 = self.spacy_summarization(text2_normalized, self.tokenizedAbstractSents_counts[0])\n",
    "        spacy_summarization3 = self.spacy_summarization(text3_normalized, self.tokenizedAbstractSents_counts[0])\n",
    "        spacy_summarization1_text = ''\n",
    "        for sent in spacy_summarization1:\n",
    "            spacy_summarization1_text += str(sent)\n",
    "        print(\"___________________spacy frequency summarized text 1:\")\n",
    "        print(spacy_summarization1_text)\n",
    "        spacy_summarization2_text = ''\n",
    "        for sent in spacy_summarization2:\n",
    "            spacy_summarization2_text += str(sent)\n",
    "        print(\"___________________spacy frequency summarized text 1:\")\n",
    "        print(spacy_summarization2_text)\n",
    "        spacy_summarization3_text = ''\n",
    "        for sent in spacy_summarization3:\n",
    "            spacy_summarization3_text += str(sent)\n",
    "        print(\"___________________spacy frequency summarized text 1:\")\n",
    "        print(spacy_summarization3_text)\n",
    "        self.spacy_extraction_summarizations = []\n",
    "        self.spacy_extraction_summarizations.append(spacy_summarization1_text)\n",
    "        self.spacy_extraction_summarizations.append(spacy_summarization2_text)\n",
    "        self.spacy_extraction_summarizations.append(spacy_summarization3_text)\n",
    "        self.df['spacy_extraction_summarization'] = self.spacy_extraction_summarizations\n",
    "        return self.df\n",
    "    \n",
    "    def _modelComparsion(self):\n",
    "        AI_genims_scores,AI_latent_scores,AI_frequency_scores = self.getAIScoreByMetric(self.df)\n",
    "        print(\"___________________AI_genims_scores:\")\n",
    "        print(AI_genims_scores)\n",
    "        print(\"___________________AI_latent_scores:\")\n",
    "        print(AI_latent_scores)\n",
    "        print(\"___________________AI_frequency_scores:\")\n",
    "        print(AI_frequency_scores)\n",
    "        self.df['AI_genims_scores']=AI_genims_scores\n",
    "        self.df['AI_latent_scores']=AI_latent_scores\n",
    "        self.df['AI_frequency_scores']=AI_frequency_scores\n",
    "        return self.df\n",
    "\n",
    "    def _selectBestModel(self):\n",
    "#         self.gensim_summarizations = []\n",
    "#         self.latent_semantic_summarizations = []\n",
    "#         self.spacy_extraction_summarizations = []\n",
    "        best_model = ''\n",
    "        AI_genims_scores_avg = self.generateTfidScores(self.gensim_summarizations)\n",
    "        print(\"___________________AI_genims_scores_avg:\")\n",
    "        print(AI_genims_scores_avg)\n",
    "        \n",
    "        AI_latent_scores_avg = self.generateTfidScores(self.latent_semantic_summarizations)\n",
    "        print(\"___________________AI_latent_scores_avg:\")\n",
    "        print(AI_latent_scores_avg)\n",
    "        \n",
    "        AI_frequency_scores_avg = self.generateTfidScores(self.spacy_extraction_summarizations)\n",
    "        print(\"___________________AI_frequency_scores_avg:\")\n",
    "        print(AI_frequency_scores_avg)\n",
    "        max_score = np.max([AI_genims_scores_avg, AI_latent_scores_avg, AI_frequency_scores_avg])\n",
    "        print(\"___________________The best score:\")\n",
    "        print(max_score)\n",
    "        return best_model\n",
    "    \n",
    "    #note, this function is only for filtering stop word, later on, we will have to stem words, and group words\n",
    "    def filterStopWords(self, text, lang):\n",
    "\n",
    "        # by default it is english lang\n",
    "        if lang is None:\n",
    "            lang = 'english'\n",
    "        new_text = ''\n",
    "        extra_arr = []\n",
    "        stop_words = set(stopwords.words(lang)) \n",
    "        stop_words.update(extra_arr)\n",
    "        word_tokens = word_tokenize(text) \n",
    "        one_text_new = [w for w in word_tokens if not w in stop_words] \n",
    "        new_text = \" \".join(one_text_new) \n",
    "        return new_text\n",
    "    \n",
    "    # filter special characts, including line changing character, redundant spaces and lower case all text\n",
    "    def filterSpecialCharsAndLowerCase(self, text):\n",
    "        #get rid of chaning line char\n",
    "        text = text.replace(\"\\n\",\" \")\n",
    "        #get rid of leading and tail spaces\n",
    "        text = text.strip()\n",
    "        #clean up non-alpha character\n",
    "        temp_new = ''\n",
    "        for word in text.split():\n",
    "            alpha_word = re.sub('[^a-z A-Z0-9\\.,\\?\\!\\'\\\"\\[\\]\\(\\)]+', ' ', word)\n",
    "            temp_new += alpha_word\n",
    "            temp_new += \" \"\n",
    "        #nomalize text making them all lower case\n",
    "        text = temp_new.lower()\n",
    "        return text\n",
    "    \n",
    "    # filter html tag\n",
    "    def filterHtmlTag(self, text):\n",
    "        #clean up html tag:\n",
    "        cleanr = re.compile('<.*?>')\n",
    "        one_text_new = re.sub(cleanr, ' ', str(text))\n",
    "        return one_text_new\n",
    "    \n",
    "    def normalizeText(self, text):\n",
    "        #filter html tag\n",
    "        text = self.filterHtmlTag(text)\n",
    "        #filter apostroph\n",
    "        text = self.filterSpecialCharsAndLowerCase(text)\n",
    "        text = self.filterStopWords(text, 'english')\n",
    "        return text\n",
    "    \n",
    "    def countHumanAbstractSents(self):\n",
    "        abstract1_normalized = self.df.loc[0]['abstract']\n",
    "        abstract2_normalized = self.df.loc[1]['abstract']\n",
    "        abstract3_normalized = self.df.loc[2]['abstract']    \n",
    "        \n",
    "        abstract1_sent_arr = sent_tokenize(abstract1_normalized)\n",
    "        self.tokenizedAbstractSents.append(abstract1_sent_arr)\n",
    "        self.tokenizedAbstractSents_counts.append(len(abstract1_sent_arr))\n",
    "        abstract2_sent_arr = sent_tokenize(abstract2_normalized)\n",
    "        self.tokenizedAbstractSents.append(abstract2_sent_arr)\n",
    "        self.tokenizedAbstractSents_counts.append(len(abstract2_sent_arr))\n",
    "        abstract3_sent_arr = sent_tokenize(abstract3_normalized)\n",
    "        self.tokenizedAbstractSents.append(abstract3_sent_arr)\n",
    "        self.tokenizedAbstractSents_counts.append(len(abstract3_sent_arr))\n",
    "\n",
    "        abstract1_word_arr = word_tokenize(abstract1_normalized)\n",
    "        self.tokenizedAbstractwords.append(abstract1_word_arr)\n",
    "        self.tokenizedAbstractwords_counts.append(len(abstract1_word_arr))\n",
    "        abstract2_word_arr = word_tokenize(abstract2_normalized)\n",
    "        self.tokenizedAbstractwords.append(abstract2_word_arr)\n",
    "        self.tokenizedAbstractwords_counts.append(len(abstract2_word_arr))\n",
    "        abstract3_word_arr = word_tokenize(abstract3_normalized)\n",
    "        self.tokenizedAbstractwords.append(abstract3_word_arr)\n",
    "        self.tokenizedAbstractwords_counts.append(len(abstract3_word_arr))\n",
    "        \n",
    "    def countTextSents(self):        \n",
    "        text1_normalized = self.df.loc[0]['normalized_text']\n",
    "        text2_normalized = self.df.loc[1]['normalized_text']\n",
    "        text3_normalized = self.df.loc[2]['normalized_text'] \n",
    "        \n",
    "        text1_sent_arr = sent_tokenize(text1_normalized)\n",
    "        self.tokenizedSents.append(text1_sent_arr)\n",
    "        self.tokenizedSents_counts.append(len(text1_sent_arr))\n",
    "        text2_sent_arr = sent_tokenize(text2_normalized)\n",
    "        self.tokenizedSents.append(text2_sent_arr)\n",
    "        self.tokenizedSents_counts.append(len(text2_sent_arr))\n",
    "        text3_sent_arr = sent_tokenize(text3_normalized)\n",
    "        self.tokenizedSents.append(text3_sent_arr)\n",
    "        self.tokenizedSents_counts.append(len(text3_sent_arr))\n",
    "        self.df['sent_tokens'] = self.tokenizedSents\n",
    "        self.df['sent_tokens_counts'] = self.tokenizedSents_counts\n",
    "\n",
    "        text1_word_arr = word_tokenize(text1_normalized)\n",
    "        self.tokenizedwords.append(text1_word_arr)\n",
    "        self.tokenizedwords_counts.append(len(text1_word_arr))\n",
    "        text2_word_arr = word_tokenize(text2_normalized)\n",
    "        self.tokenizedwords.append(text2_word_arr)\n",
    "        self.tokenizedwords_counts.append(len(text2_word_arr))\n",
    "        text3_word_arr = word_tokenize(text3_normalized)\n",
    "        self.tokenizedwords.append(text3_word_arr)\n",
    "        self.tokenizedwords_counts.append(len(text3_word_arr))\n",
    "        self.df['word_tokens'] = self.tokenizedwords\n",
    "        self.df['word_tokens_counts'] = self.tokenizedwords_counts\n",
    "    \n",
    "    ##### Try building the vectors before feeding them to the cosine_distance function:\n",
    "    def similar(self, l1, l2, metric=cluster.util.cosine_distance):\n",
    "        iterable1 = l1.split()\n",
    "        iterable2 = l2.split()\n",
    "        counter1 = Counter(iterable1)\n",
    "        counter2= Counter(iterable2)\n",
    "        all_items = set(counter1.keys()).union( set(counter2.keys()) )\n",
    "        vector1 = [counter1[k] for k in all_items]\n",
    "        vector2 = [counter2[k] for k in all_items]\n",
    "        s1 = set(iterable1)\n",
    "        s2 = set(iterable2)\n",
    "        result_metric = metric(vector1, vector2)\n",
    "        return result_metric\n",
    "\n",
    "    ##### give scores of each questions automatically based on metrics cosine_distance\n",
    "    def getAIScoreByMetric(self, df, metric=cluster.util.cosine_distance):\n",
    "        self.AI_genims_scores = []\n",
    "        self.AI_latent_scores = []\n",
    "        self.AI_frequency_scores = []\n",
    "        for i in range(0, len(df)):\n",
    "            Reference = df.loc[i]['abstract']\n",
    "            Sample_genims = df.loc[i]['gensim_summarizations']\n",
    "            Sample_latent = df.loc[i]['latent_semantic_summarization']\n",
    "            Sample_frequency = df.loc[i]['spacy_extraction_summarization']\n",
    "            AI_genims_score = 1 - self.similar(Reference, Sample_genims)\n",
    "            self.AI_genims_scores.append(AI_genims_score)\n",
    "            AI_latent_score = 1 - self.similar(Reference, Sample_latent)\n",
    "            self.AI_latent_scores.append(AI_latent_score)\n",
    "            AI_frequency_score = 1 - self.similar(Reference, Sample_frequency)\n",
    "            self.AI_frequency_scores.append(AI_frequency_score)\n",
    "        return self.AI_genims_scores, self.AI_latent_scores, self.AI_frequency_scores\n",
    "    \n",
    "    # Use TfidfVectorizer() to transform the summarizations into vectors,\n",
    "    # then compute their cosine similarity.    \n",
    "    def cosine(self, text1, text2):\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf = vectorizer.fit_transform([text1, text2])\n",
    "        return ((tfidf * tfidf.T).A)[0,1]\n",
    "    \n",
    "    def generateTfidScores(self, model_summury):\n",
    "        self.Tfidf_scores = []\n",
    "        # text_summuarization_df._selectBestModel()\n",
    "        for i in range(len(self.abstracts)):\n",
    "            score = self.cosine(self.abstracts[i], model_summury[i])\n",
    "            self.Tfidf_scores.append(score)\n",
    "        # Plot the scores\n",
    "        plt.figure(figsize=(12,4))\n",
    "        # plt.hist(text_summuarization_df.Tfidf_scores, bins = 3)\n",
    "        # plt.xlim([1,2,3])\n",
    "        # plt.ylim(0,np.max(text_summuarization_df.Tfidf_scores))\n",
    "        x = np.arange(3)\n",
    "        plt.bar(x, height=self.Tfidf_scores)\n",
    "        plt.xticks(x, ['text1','text2','text3'])\n",
    "        plt.show()\n",
    "        return np.mean(self.Tfidf_scores)\n",
    "        \n",
    "    # Function to report the quality of the model\n",
    "    def performance(value, score_list):\n",
    "        # the value (0-1) is the cosine similarity score to determine how close to human summarization\n",
    "        # have the same meaning or not.\n",
    "        scores = []\n",
    "        for score in score_list:\n",
    "            if score >= value:\n",
    "                scores.append(1)\n",
    "            else:\n",
    "                scores.append(0)\n",
    "\n",
    "        accuracy = accuracy_score(df.is_duplicate, scores) * 100\n",
    "        print(\"Accuracy score is {}%.\".format(round(accuracy),1))\n",
    "        print()\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(df.is_duplicate, scores))\n",
    "        print()\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(df.is_duplicate, scores))\n",
    "        \n",
    "    #Latent Semantic Analysis approach\n",
    "    #The following code was modified based on https://github.com/luisfredgs/LSA-Text-Summarization/blob/master/lsa_summarizer.py\n",
    "    #Paper: https://www.researchgate.net/publication/220195824_Text_summarization_using_Latent_Semantic_Analysis \n",
    "    def create_dictionary(self, text):\n",
    "        \"\"\"Creates mapping key = word, value = row index\"\"\"\n",
    "        words = word_tokenize(text)\n",
    "        words = tuple(words)\n",
    "        unique_words = frozenset(w for w in words)\n",
    "\n",
    "        return dict((w, i) for i, w in enumerate(unique_words))\n",
    "\n",
    "    def create_matrix(self, sentences, dictionary):\n",
    "        \"\"\"\n",
    "        Creates matrix of shape where cells\n",
    "        contains number of occurences of words (rows) in senteces (cols).\n",
    "        \"\"\"\n",
    "        words_count = len(dictionary)\n",
    "        sentences_count = len(sentences)\n",
    "        if words_count < sentences_count:\n",
    "            message = (\n",
    "                \"Number of words (%d) is lower than number of sentences (%d). \"\n",
    "                \"LSA algorithm may not work properly.\"\n",
    "            )\n",
    "            warn(message % (words_count, sentences_count))\n",
    "\n",
    "        matrix = np.zeros((words_count, sentences_count))\n",
    "        for col, sentence in enumerate(sentences):\n",
    "            words = word_tokenize(sentence)\n",
    "            for word in words:\n",
    "                # only valid words is counted (not stop-words, ...)\n",
    "                if word in dictionary:\n",
    "                    row = dictionary[word]\n",
    "                    matrix[row, col] += 1\n",
    "\n",
    "        return matrix\n",
    "\n",
    "    def compute_term_frequency(self, matrix, smooth=0.4):\n",
    "        \"\"\"\n",
    "        Computes TF metrics for each sentence (column) in the given matrix and  normalize \n",
    "        the tf weights of all terms occurring in a document by the maximum tf in that document \n",
    "        according to ntf_{t,d} = a + (1-a)\\frac{tf_{t,d}}{tf_{max}(d)^{'}}.\n",
    "\n",
    "        The smoothing term $a$ damps the contribution of the second term - which may be viewed \n",
    "        as a scaling down of tf by the largest tf value in $d$\n",
    "        \"\"\"\n",
    "        assert 0.0 <= smooth < 1.0\n",
    "\n",
    "        max_word_frequencies = np.max(matrix, axis=0)\n",
    "        rows, cols = matrix.shape\n",
    "        for row in range(rows):\n",
    "            for col in range(cols):\n",
    "                max_word_frequency = max_word_frequencies[col]\n",
    "                if max_word_frequency != 0:\n",
    "                    frequency = matrix[row, col]/max_word_frequency\n",
    "                    matrix[row, col] = smooth + (1.0 - smooth)*frequency\n",
    "\n",
    "        return matrix\n",
    "\n",
    "\n",
    "    def compute_ranks(self, sigma, v_matrix):\n",
    "        assert len(sigma) == v_matrix.shape[0]\n",
    "\n",
    "        dimensions = max(self.MIN_DIMENSIONS,\n",
    "            int(len(sigma)*self.REDUCTION_RATIO))\n",
    "        powered_sigma = tuple(s**2 if i < dimensions else 0.0\n",
    "            for i, s in enumerate(sigma))\n",
    "\n",
    "        ranks = []\n",
    "\n",
    "        for column_vector in v_matrix.T:\n",
    "            rank = sum(s*v**2 for s, v in zip(powered_sigma, column_vector))\n",
    "            ranks.append(math.sqrt(rank))\n",
    "\n",
    "        return ranks\n",
    "\n",
    "    # SentenceInfo = namedtuple(\"SentenceInfo\", (\"sentence\", \"order\", \"rating\",))\n",
    "\n",
    "    def sortFunc(self, e):\n",
    "        return e['rating']\n",
    "\n",
    "    def get_best_sentences(self, sentences, count, rating):\n",
    "        rate = rating\n",
    "        infos = []\n",
    "        print(count, len(rating))\n",
    "        for o, s in enumerate(sentences):\n",
    "    #         print(o, s, rate[o])\n",
    "            infos.append({'sentence':s, 'order':o, 'rating':rate[o]})\n",
    "        # sort sentences by rating in descending order\n",
    "        infos.sort(reverse=True, key=self.sortFunc)\n",
    "        infos = infos[:count]\n",
    "        # sort sentences by their order in document\n",
    "        infos.sort(key=self.sortFunc)\n",
    "        return list(i['sentence'] for i in infos)\n",
    "    \n",
    "    #Spacy Model code was modified based on https://github.com/luisfredgs/extractive-text-summarization\n",
    "    def spacy_summarization(self, text, sents_count):\n",
    "\n",
    "        doc = nlp(text)\n",
    "        corpus = [sent.text.lower() for sent in doc.sents ]\n",
    "        cv = CountVectorizer(stop_words=list(STOP_WORDS))   \n",
    "        cv_fit=cv.fit_transform(corpus)    \n",
    "        word_list = cv.get_feature_names();    \n",
    "        count_list = cv_fit.toarray().sum(axis=0)    \n",
    "\n",
    "        \"\"\"\n",
    "        The zip(*iterables) function takes iterables as arguments and returns an iterator. \n",
    "        This iterator generates a series of tuples containing elements from each iterable. \n",
    "        Let's convert these tuples to {word:frequency} dictionary\"\"\"\n",
    "\n",
    "    #     //the world is good\n",
    "    # the: 0.1, world: 0.2, is : 0.3, good: 0.4 -> the whole sentence: total\n",
    "        word_frequency = dict(zip(word_list,count_list))\n",
    "\n",
    "        val=sorted(word_frequency.values())\n",
    "\n",
    "        # Check words with higher frequencies\n",
    "        higher_word_frequencies = [word for word,freq in word_frequency.items() if freq in val[-3:]]\n",
    "        print(\"\\nWords with higher frequencies: \", higher_word_frequencies)\n",
    "\n",
    "        # gets relative frequencies of words\n",
    "        higher_frequency = val[-1]\n",
    "        for word in word_frequency.keys():  \n",
    "            word_frequency[word] = (word_frequency[word]/higher_frequency)\n",
    "\n",
    "\n",
    "        # SENTENCE RANKING: the rank of sentences is based on the word frequencies\n",
    "        sentence_rank={}\n",
    "        for sent in doc.sents:\n",
    "            for word in sent :       \n",
    "                if word.text.lower() in word_frequency.keys():            \n",
    "                    if sent in sentence_rank.keys():\n",
    "                        sentence_rank[sent]+=word_frequency[word.text.lower()]\n",
    "                    else:\n",
    "                        sentence_rank[sent]=word_frequency[word.text.lower()]\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "        sentence_rank_val =list(sentence_rank.values())\n",
    "        sentence_rank_val.sort(reverse=True)\n",
    "        top_sent=sentence_rank_val[sents_count]\n",
    "\n",
    "        # Mount summary\n",
    "        summary=[]\n",
    "        for sent,strength in sentence_rank.items():  \n",
    "            if strength >= top_sent:\n",
    "                summary.append(sent)\n",
    "\n",
    "        # return orinal text and summary\n",
    "        return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: initilize the assignment 4 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_summuarization_df = solutionGuildeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: extract the raw text from 3 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>abstract</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>sent_tokens_counts</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>word_tokens_counts</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>gensim_summarizations</th>\n",
       "      <th>latent_semantic_summarization</th>\n",
       "      <th>spacy_extraction_summarization</th>\n",
       "      <th>AI_genims_scores</th>\n",
       "      <th>AI_latent_scores</th>\n",
       "      <th>AI_frequency_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Strategies and Best Practices for Data Literac...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe External Effects of Bl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\nComparative analysis of the main busines...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text abstract sent_tokens  \\\n",
       "0  Strategies and Best Practices for Data Literac...      NaN         NaN   \n",
       "1  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe External Effects of Bl...      NaN         NaN   \n",
       "2  \\n\\n\\nComparative analysis of the main busines...      NaN         NaN   \n",
       "\n",
       "  sent_tokens_counts word_tokens word_tokens_counts normalized_text  \\\n",
       "0                NaN         NaN                NaN             NaN   \n",
       "1                NaN         NaN                NaN             NaN   \n",
       "2                NaN         NaN                NaN             NaN   \n",
       "\n",
       "  gensim_summarizations latent_semantic_summarization  \\\n",
       "0                   NaN                           NaN   \n",
       "1                   NaN                           NaN   \n",
       "2                   NaN                           NaN   \n",
       "\n",
       "  spacy_extraction_summarization AI_genims_scores AI_latent_scores  \\\n",
       "0                            NaN              NaN              NaN   \n",
       "1                            NaN              NaN              NaN   \n",
       "2                            NaN              NaN              NaN   \n",
       "\n",
       "  AI_frequency_scores  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_summuarization_df._dataExtraction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: preprocess the raw text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>abstract</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>sent_tokens_counts</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>word_tokens_counts</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>gensim_summarizations</th>\n",
       "      <th>latent_semantic_summarization</th>\n",
       "      <th>spacy_extraction_summarization</th>\n",
       "      <th>AI_genims_scores</th>\n",
       "      <th>AI_latent_scores</th>\n",
       "      <th>AI_frequency_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Strategies and Best Practices for Data Literac...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>strategies best practices data literacy educat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe External Effects of Bl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>external effects black male incarceration blac...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\nComparative analysis of the main busines...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>comparative analysis main business processes b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text abstract sent_tokens  \\\n",
       "0  Strategies and Best Practices for Data Literac...      NaN         NaN   \n",
       "1  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe External Effects of Bl...      NaN         NaN   \n",
       "2  \\n\\n\\nComparative analysis of the main busines...      NaN         NaN   \n",
       "\n",
       "  sent_tokens_counts word_tokens word_tokens_counts  \\\n",
       "0                NaN         NaN                NaN   \n",
       "1                NaN         NaN                NaN   \n",
       "2                NaN         NaN                NaN   \n",
       "\n",
       "                                     normalized_text gensim_summarizations  \\\n",
       "0  strategies best practices data literacy educat...                   NaN   \n",
       "1  external effects black male incarceration blac...                   NaN   \n",
       "2  comparative analysis main business processes b...                   NaN   \n",
       "\n",
       "  latent_semantic_summarization spacy_extraction_summarization  \\\n",
       "0                           NaN                            NaN   \n",
       "1                           NaN                            NaN   \n",
       "2                           NaN                            NaN   \n",
       "\n",
       "  AI_genims_scores AI_latent_scores AI_frequency_scores  \n",
       "0              NaN              NaN                 NaN  \n",
       "1              NaN              NaN                 NaN  \n",
       "2              NaN              NaN                 NaN  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_summuarization_df._preprocessData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: generate additional features to help with modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>abstract</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>sent_tokens_counts</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>word_tokens_counts</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>gensim_summarizations</th>\n",
       "      <th>latent_semantic_summarization</th>\n",
       "      <th>spacy_extraction_summarization</th>\n",
       "      <th>AI_genims_scores</th>\n",
       "      <th>AI_latent_scores</th>\n",
       "      <th>AI_frequency_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Strategies and Best Practices for Data Literac...</td>\n",
       "      <td>2012 , analysts estimated 90 world data come e...</td>\n",
       "      <td>[strategies best practices data literacy educa...</td>\n",
       "      <td>2863</td>\n",
       "      <td>[strategies, best, practices, data, literacy, ...</td>\n",
       "      <td>48070</td>\n",
       "      <td>strategies best practices data literacy educat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe External Effects of Bl...</td>\n",
       "      <td>article examines increase incarceration black ...</td>\n",
       "      <td>[external effects black male incarceration bla...</td>\n",
       "      <td>686</td>\n",
       "      <td>[external, effects, black, male, incarceration...</td>\n",
       "      <td>12116</td>\n",
       "      <td>external effects black male incarceration blac...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\nComparative analysis of the main busines...</td>\n",
       "      <td>work aims present study business processes sma...</td>\n",
       "      <td>[comparative analysis main business processes ...</td>\n",
       "      <td>437</td>\n",
       "      <td>[comparative, analysis, main, business, proces...</td>\n",
       "      <td>6933</td>\n",
       "      <td>comparative analysis main business processes b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Strategies and Best Practices for Data Literac...   \n",
       "1  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe External Effects of Bl...   \n",
       "2  \\n\\n\\nComparative analysis of the main busines...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  2012 , analysts estimated 90 world data come e...   \n",
       "1  article examines increase incarceration black ...   \n",
       "2  work aims present study business processes sma...   \n",
       "\n",
       "                                         sent_tokens  sent_tokens_counts  \\\n",
       "0  [strategies best practices data literacy educa...                2863   \n",
       "1  [external effects black male incarceration bla...                 686   \n",
       "2  [comparative analysis main business processes ...                 437   \n",
       "\n",
       "                                         word_tokens  word_tokens_counts  \\\n",
       "0  [strategies, best, practices, data, literacy, ...               48070   \n",
       "1  [external, effects, black, male, incarceration...               12116   \n",
       "2  [comparative, analysis, main, business, proces...                6933   \n",
       "\n",
       "                                     normalized_text gensim_summarizations  \\\n",
       "0  strategies best practices data literacy educat...                   NaN   \n",
       "1  external effects black male incarceration blac...                   NaN   \n",
       "2  comparative analysis main business processes b...                   NaN   \n",
       "\n",
       "  latent_semantic_summarization spacy_extraction_summarization  \\\n",
       "0                           NaN                            NaN   \n",
       "1                           NaN                            NaN   \n",
       "2                           NaN                            NaN   \n",
       "\n",
       "  AI_genims_scores AI_latent_scores AI_frequency_scores  \n",
       "0              NaN              NaN                 NaN  \n",
       "1              NaN              NaN                 NaN  \n",
       "2              NaN              NaN                 NaN  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_summuarization_df._featurePreparation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Gensim Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________genism summarized text 1:\n",
      "Best practices for teaching data literacy education include  collaboration between educators, organizations, and institutions to ensure  goals are  being met by all stakeholders; diverse  and creative  teaching approaches and environment including the effective  use of technology; successive/iterative learning with  complementary skills integrated (e.g.\n",
      "These include geospatial data literacy  and GIS; sector-­--specific  and industry-­--driven  data literacy requirements with  input from outside of academic institutions; no standard  for assessing or evaluating data  literacy levels; data security training for students without a computer science background; the ethics  of data and data-­--driven  decision-­--making; and how to provide data literacy training to the existing workforce in addition to new graduates.\n",
      "Our team will continue work in this area; we are developing a data literacy assessment tool, we have applied for academic innovation funding to produce course materials based on  the results of this synthesis, and we will share the knowledge we''ve synthesized in appropriate venues.\n",
      "Thus, our team has drafted  a knowledge synthesis  based on a review of formal and informal literature that seeks  to understand and share best practices for teaching  data literacy  at the postsecondary  level.\n",
      "By teaching data foundational literacy competencies early on in a postsecondary student’s academic career, students are  more  likely to learn lifelong skills that will allow them to effectively and dynamically work with data and  fully participate in  the economy of today, and  tomorrow.\n",
      "This process began  with  a systematic review, searching relevant electronic  databases, grey literature, white papers, and governmental reports and policies for quantitative and qualitative studies to determine data literacy competencies, skills, and  abilities, as well as teaching practices for undergraduate students.\n",
      "This includes practices that are non-­--traditional but already employed at post-­--secondary institutions, like incorporating both formal  and informal  teaching methods into education, and providing students with tools and encouragement to develop skills outside of class, tutorials, and labs.\n",
      "A  data literacy self assessment tool, informed by a need-­--driven  competencies matrix like the one in Appendix  1, will help track success  at imparting necessary knowledge and skills  to students.\n",
      "Institute: University of Delaware Name: Analytics: Optimizing Big Data Certificate Type: In-­--person  Course Description: This continuing education  course offered  by the University of Delaware aims to teach  students  how to gather, organize, and effectively analyze large datasets  in order  to make informed business decisions.Students are also  taught how to  communicate their analyses in a clear and concise manner.\n",
      "Authors/Source Carlson, Fosmire, Miller, and Sapp Nelson (2011; Carlson, Johnston, Westra, and Nichols, 2012)  Data Citation  Basic Data Analysis  Data Visualization  Presenting Data (Verbally)  Data Interpratation (Understanding Data)  Identifying Problems Using Data  Data Driven Decision Making (DDDM)  Evaluating Decisions/Conclusions Based on Data  Metadata Creation and Use  \n",
      "The focus is on entrepreneurship, but these skills can be applied to data literacy and 21st century skills and literacies in general, such as the ability to think and reason logically in an effort to solve complex problems, open-ended problems, and goes hand in hand with critical analysis ensuring useful and relevant results; as well as application of analysis, inference and interpretation, evaluation, and synthesis to develop new solutions to complex problems \n",
      "Purdue Team 2 Agricultural and Standard Operating Procedures Workshops Biological Metadata Engineering Minnesota Civil Engineering Data Ownership, Long-Term Access Online Course Oregon Ecology Cultures of Practice, Data Sharing & Readings and Metadata, Closing Out a Grant Team Meetings * There is more detailed information about case studies, but not overly useful The methodology used in the first part of this study was interviews with faculty, and recent graduates, to identify gaps, define most important competencies, and highlight the differing interpretations based on disciplinary experiences.\n",
      "Theme(s): 21st Century Skills and Literacies, Delivery and Assessment Contribution: This peer-reviewed article, written by Czerkawski and Lyman, argues that computational thinking (CT) is a useful skill across all disciplines, because it is a mental process to solve problems and discover solutions, using logic, algorithmic thinking, recursive thinking, abstraction, parallel thinking, pattern-matching and related processes This paper focuses on STEM faculties; it can be incorporated into humanities learning, but this would be more difficult, due to the primarily text based analysis.\n",
      "In terms of content delivery, although online courses and texts on data and statistical literacy are useful, user-targeted specific assistance and teaching is often needed (e.g.for users with differing skill levels, or users studying a specific discipline).\n",
      "This type of support is recognized in relation to the dual nature of data literacy education: target appropriate audience and provide able professional support and training; re-skilling may be essential to the success of programs, and librarians are a great resource in helping with this Koltay lists Carlson, Qin, Schneider, Calzada, and Mandinach and Gummer’s varying definitions and competencies of data literacy, and argues that there should be only one definition; many definitions overlap with different terms, but the meaning is the same, and most recognize the difference between producer and creator, and the importance of including each.\n",
      "DOI: 10.3102/0013189X12459803 Theme(s): Barriers to Effective Data Literacy Instruction, Data Literacy As The Ability To Understand And Use Data Effectively To Inform Decisions, Data Literacy Competencies and Skills, Delivery and Assessment, Teach the Teacher Contribution: Mandinach and Gummer present the context and trends surrounding data literacy from the perspective of educating pre-service teachers, including supportive technologies, standards, and accreditation.\n",
      "http://dx.doi.org/10.1016/j.tate.2015.05.007 Theme(s): Barriers to Effective Data Literacy Instruction, Delivery and Assessment, Teach the Teacher Contribution: Reeves and Honig’s peer reviewed article focuses on pre-service teachers learning how to use data to evaluate student outcomes.\n",
      "certificate is similar to full study, but geared towards people already in the field with a need to improve skills and competencies Schneider based the course on three studies: Shapiro and Hughes provides basis for data literacy curriculum as tool literacy, resource literacy, socio-cultural literacy, emerging technology literacy, and critical literacy; Eisenberg’s Information Literacy (2008) defines essential skills that relate to data literacy as ability to clarify, locate, select/analyze, organize/synthesize, create/present, and evaluate information; and the Working Group on Information Literacy defines seven pillars that align with data literacy as identify, scope, plan, gather, evaluate, manage, and present/provide Research Data Literacy Data Management Competencies Identify Documentation (research environmental, temporal) / Context / From Information Management to Knowledge Management Scope Monitoring Process / Extracting Information from Data Models (and People) Plan Data Modeling / Metadata / Standards Development Store Data Analysis and Manipulation / Merging, Mashing, Integration  \n",
      "Retrieved from http://ojs.library.ubc.ca/index.php/seealso/article/view/186335 Theme(s): 21st Century Skills and Literacies, Barriers to Effective Data Literacy Instruction, Delivery and Assessment,Teach the Teacher Contribution: Wanner’s peer-reviewed article examines existing literature related to data literacy from both producer (research data management, and consumer (functional use) perspectives, and focuses on two questions while reviewing publications: What is data literacy and how does it differ from its counterpart, information literacy?\n",
      "doi:10.1098/rsta.2008.0118 Theme(s): 21st Century Skills and Literacies, Data Literacy Best Taught At The Commencement of Post-Secondary Studies, Delivery and Assessment Contribution: Wing introduces the concept of Computational Thinking (CT) as requiring people be attuned to science, technology, and society, because the fundamental concepts are solving problems, designing systems, and understanding human behaviour.\n",
      "Theme(s): Data Literacy As The Ability To Understand And Use Data Effectively To Inform Decisions, Delivery and Assessment Contribution: Wyner’s peer-reviewed article focuses on Master level students in science education, with a goal to make connections between data and human impact on daily life and sustainability.\n",
      "These skills can be developed through several ways, including professional conferences, reviewing key documents relating to data science, formal and informal training programs, and continually working to understand perspectives, practices, and culture (lifelong learning).\n",
      "Theme(s): 21st Century Skills and Literacies, Data Literacy As The Ability To Understand And Use Data Effectively To Inform Decisions, Data Literacy Competencies and Skills, Delivery and Assessment Contribution: Gunter argues that in today’s society, there is a perpetual struggle to provide students with objectives and strategies to develop skills to be competitive in the new global economy.\n",
      "___________________genism summarized text 2:\n",
      "Combining data from the Bureau of Justice Statistics and the Current Population Survey to match male incar- ceration rates with individual observations over two decades, I show that black male incarceration lowers the odds of black non- marital teenage fertility while increasing young black women’s school attainment and early employment.\n",
      "To examine how the rising levels of incarceration of black men lead young black women to change important lifetime decisions, I compiled data on the number of male prisoners by race, gender, state, and year from the Bureau of Justice Statistics (BJS).\n",
      "This enables me to fexibly link male incarceration rates with individual female observations5 and to better pinpoint which states and subperiods are driving the results; second, I use a more comprehensive set of controls, in particular through using the list of welfare policy var- iables analyzed in Fang and Keane (2004) and through checking whether women were born before or after abortion legalization (imputing state of birth with state of residence at the time of survey).\n",
      "___________________genism summarized text 3:\n",
      "Thus, the study allowed the development of a basic model that presents the best practices based on the PCF model (Process Classification Framework), in view of, adequate and compatible with the reality of the organizations that work in the subsector of buildings.\n",
      "During the development of this research it was observed what actually happens in the construction environment of the day to day, it has been a good way to find out that to manage business processes, firstly, it is necessary to visualize them end to end and document them, to be able to define work patterns, avoid redundant processes, or even design new processes.\n",
      "Thus, the model and process mappings, relevant practical examples, contained in this study, besides motivate the interest of building companies, can also induce other industries to perform modeling to conceptualize its processes and know the sequence of work activities, thus creating its own business process architecture.\n",
      "(2012) and Holt & Perry (2010), the process modeling produces abstract descriptions of business processes, making it a fundamental asset for companies, since they allow to identify the complexity, ading the understanding of documents, improving communication, as well as accomplish analysis and engineering through multiple paradigms, languages and techniques.\n",
      "Song & Choi (2011) suggested a Sustainable Business Process Management model (SBPM), which allows the continuous improvement of the business processes of companies in the civil construction sector.\n",
      "Most companies internally carry out processes such as prospecting for new constructions and business, coordination and planning of projects, preparation and analysis of budget, process of purchase of materials and services, sales and marketing, financial management, human resources (HR) management, management of construction site.\n",
      "Business processes such as project coordination and planning, commercialization of buildings, budget preparation and analysis, acquisition of materials and services, execution of constructions, after-sales services, management of outsourced services, health management, the environment and work safety and the prospecting of new buildings are typical of the small companies of the sub-sector of buildings.\n",
      "Front to the informations collected, based on the interviews conducted with the companies participating in the research, the basic model summarizes the main business processes: (1) Develop vision and strategy, (2) Coordinate and plan projects, (3) Elaborate and analyze of budget, (4) Sell buildings, (5) Acquiring materials and services, (6) Execute and manage construction site, (7) After sales service, (8) Manage human resources, (9) Manage outsourced services, (10) Manage health, environment and safety, (11) Manage finances and resources and (12) Prospect new constructions and businesses.\n",
      "The study is limited to a basic model of business processes that was developed from mapping the activities applied in construction companies.\n",
      "Sustainable business process management model for construction companies.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>abstract</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>sent_tokens_counts</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>word_tokens_counts</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>gensim_summarizations</th>\n",
       "      <th>latent_semantic_summarization</th>\n",
       "      <th>spacy_extraction_summarization</th>\n",
       "      <th>AI_genims_scores</th>\n",
       "      <th>AI_latent_scores</th>\n",
       "      <th>AI_frequency_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Strategies and Best Practices for Data Literac...</td>\n",
       "      <td>2012 , analysts estimated 90 world data come e...</td>\n",
       "      <td>[strategies best practices data literacy educa...</td>\n",
       "      <td>2863</td>\n",
       "      <td>[strategies, best, practices, data, literacy, ...</td>\n",
       "      <td>48070</td>\n",
       "      <td>strategies best practices data literacy educat...</td>\n",
       "      <td>Best practices for teaching data literacy educ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe External Effects of Bl...</td>\n",
       "      <td>article examines increase incarceration black ...</td>\n",
       "      <td>[external effects black male incarceration bla...</td>\n",
       "      <td>686</td>\n",
       "      <td>[external, effects, black, male, incarceration...</td>\n",
       "      <td>12116</td>\n",
       "      <td>external effects black male incarceration blac...</td>\n",
       "      <td>Combining data from the Bureau of Justice Stat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\nComparative analysis of the main busines...</td>\n",
       "      <td>work aims present study business processes sma...</td>\n",
       "      <td>[comparative analysis main business processes ...</td>\n",
       "      <td>437</td>\n",
       "      <td>[comparative, analysis, main, business, proces...</td>\n",
       "      <td>6933</td>\n",
       "      <td>comparative analysis main business processes b...</td>\n",
       "      <td>Thus, the study allowed the development of a b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Strategies and Best Practices for Data Literac...   \n",
       "1  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe External Effects of Bl...   \n",
       "2  \\n\\n\\nComparative analysis of the main busines...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  2012 , analysts estimated 90 world data come e...   \n",
       "1  article examines increase incarceration black ...   \n",
       "2  work aims present study business processes sma...   \n",
       "\n",
       "                                         sent_tokens  sent_tokens_counts  \\\n",
       "0  [strategies best practices data literacy educa...                2863   \n",
       "1  [external effects black male incarceration bla...                 686   \n",
       "2  [comparative analysis main business processes ...                 437   \n",
       "\n",
       "                                         word_tokens  word_tokens_counts  \\\n",
       "0  [strategies, best, practices, data, literacy, ...               48070   \n",
       "1  [external, effects, black, male, incarceration...               12116   \n",
       "2  [comparative, analysis, main, business, proces...                6933   \n",
       "\n",
       "                                     normalized_text  \\\n",
       "0  strategies best practices data literacy educat...   \n",
       "1  external effects black male incarceration blac...   \n",
       "2  comparative analysis main business processes b...   \n",
       "\n",
       "                               gensim_summarizations  \\\n",
       "0  Best practices for teaching data literacy educ...   \n",
       "1  Combining data from the Bureau of Justice Stat...   \n",
       "2  Thus, the study allowed the development of a b...   \n",
       "\n",
       "  latent_semantic_summarization spacy_extraction_summarization  \\\n",
       "0                           NaN                            NaN   \n",
       "1                           NaN                            NaN   \n",
       "2                           NaN                            NaN   \n",
       "\n",
       "  AI_genims_scores AI_latent_scores AI_frequency_scores  \n",
       "0              NaN              NaN                 NaN  \n",
       "1              NaN              NaN                 NaN  \n",
       "2              NaN              NaN                 NaN  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_summuarization_df._buildingGensimModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Latent Semantic Analysis approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 2863\n",
      "3 686\n",
      "8 437\n",
      "___________________latent_semantic summarized text 1:\n",
      "found students could apply mathematical reasoning help answer difficult social studies projects , use knowledge analyze general data literacy questions . synthesizing data different representations formulate overall conclusion solar power ( longer active ) modular program designed assess outcomes ict learning schools . speaking technology , merely possession technical infrastructure ( hardware software ) means sufficient provide comparative advantage become competitive succeed digital economy . sdl project identified two gaps su ischool could address 1. required next generation workforce manage new type information resource ( i.e . mckinsey global institute suggested current training rates , us alone 140,000 190,000 jobs trained data scientists 2018 ( manyika et al. thus , team drafted knowledge synthesis based review formal informal literature seeks understand share best practices teaching data literacy postsecondary level . article relevant terms delivery content , provides lessons surrounding assumptions made level technical skills students may going given data literacy course workshop . using tool opposed data analytics software packages database management systems allows greater accessibility , many free ( negating financial cost barrier ) . applied academic innovation funds dalhousie university support project develop modular curriculum materials based learned preparing synthesis , empirically validate theories presented literature . others recommend inclass librarian instruction helpful introducing students support data services collaboration faculty would enable library provide focused learning modules students needs , possibly providing subject based data pages already converted readily usable formats increasing referrals faculty library instruction overall critical thinking skills development would help bridge gap full curriculum intense skill development support . goes say order meet demands world live students need adapt changing conditions learn independently.this includes using technology effectively process large amounts quantitative data . survey 300 top level executives forbes identified increased customer engagement growth companies considered leaders data driven marketing decision making ( mckendrick , 2015 ) . addressed question examining existing strategies best practices teaching data literacy , synthesizing documented explicit knowledge ( formal informal literature ) using narrative synthesis methodology . disseminate results government ngo stakeholders imagining canada '' future forum november 2015 ottawa , academic audiences via journal articles conference presentations next several weeks . qin ignazio found feedback masters level students lack background knowledge makes data literacy jargon exercises difficult master especially varying skill levels group ( 2010b ) . using data analytics allows businesses carry targeted customer group campaigns , instead putting large amount resources one generalized campaign ( thereby increasing cost effectiveness ) . retrieved http docs.lib.purdue.edu lib fspres 10 theme ( ) data literacy competencies skills , delivery assessment contribution powerpoint slide deck generated sarah wright et al . also plan showcase work 19th annual dalhousie conference university teaching learning ( dcutl ) , held april 2016. includes many 200 participants across atlantic canada beyond . ( 6 ) include subskills represent various economic sectors identified important skills method used study included national international literature review , well interviews consultation key informants . retrieved http www.bizedmagazine.com archives 2014 2 research big data gets bigger campus contribution authors argue analytics related positions predicted increase 25 2018 , universities developing focused training . end project , students expected determine whether current allocation water equitable among three states ( using un convention law non navigational uses international watercourses base guideline ) .\n",
      "___________________latent_semantic summarized text 2:\n",
      "0734 306x 2011 2901 0003 10.00 1 2 mechoulan behind bars 2004.1 given current trends , one black male child three go prison jail point lifetime . , model 11 shows postponement effect concentrated frst birth stage.33 low ( adjusted ) r2 unsurprising given dealing 31 could fnd plausible exogenous background characteristics leading differential treatment within either group . overall , evidence points sizable marginal effect male incar ceration schooling grade 12 juncture among black women ( one extra percentage point incarceration associated 5 month increase education preferred specifcation elasticity p 0.23 ) .\n",
      "___________________latent_semantic summarized text 3:\n",
      "para coletar os dados realizaram se entrevistas semiestruturadas , lises de documentos e observa es diretas loco . 2.2 studies related theme research bremer lenza ( 2000 ) present reference model business process production management . pcf reference model ( process classification framework ) offers variety information organizations increase level orientation business processes . company needs design processes better serve customer , well streamline coordination internal external suppliers ( hongtao et al. companies infrastructure construction building industries facing huge pressure strengthen enhance processes due wide competition ( viljamaa peltomaa , 2014 ) . initial design pcf ( process classification framework ) involved 80 organizations strong interest promoting exchange information united states around world . comparative analysis showed existence similarities among processes , serve basis develop basic model presents guidelines apply best practices companies construction sector . com base nas informa es obtidas desenvolveu se modelagem dos processos de neg cio utilizando nota bpmn ( business process modeling notation ) .\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>abstract</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>sent_tokens_counts</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>word_tokens_counts</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>gensim_summarizations</th>\n",
       "      <th>latent_semantic_summarization</th>\n",
       "      <th>spacy_extraction_summarization</th>\n",
       "      <th>AI_genims_scores</th>\n",
       "      <th>AI_latent_scores</th>\n",
       "      <th>AI_frequency_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Strategies and Best Practices for Data Literac...</td>\n",
       "      <td>2012 , analysts estimated 90 world data come e...</td>\n",
       "      <td>[strategies best practices data literacy educa...</td>\n",
       "      <td>2863</td>\n",
       "      <td>[strategies, best, practices, data, literacy, ...</td>\n",
       "      <td>48070</td>\n",
       "      <td>strategies best practices data literacy educat...</td>\n",
       "      <td>Best practices for teaching data literacy educ...</td>\n",
       "      <td>found students could apply mathematical reason...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe External Effects of Bl...</td>\n",
       "      <td>article examines increase incarceration black ...</td>\n",
       "      <td>[external effects black male incarceration bla...</td>\n",
       "      <td>686</td>\n",
       "      <td>[external, effects, black, male, incarceration...</td>\n",
       "      <td>12116</td>\n",
       "      <td>external effects black male incarceration blac...</td>\n",
       "      <td>Combining data from the Bureau of Justice Stat...</td>\n",
       "      <td>0734 306x 2011 2901 0003 10.00 1 2 mechoulan b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\nComparative analysis of the main busines...</td>\n",
       "      <td>work aims present study business processes sma...</td>\n",
       "      <td>[comparative analysis main business processes ...</td>\n",
       "      <td>437</td>\n",
       "      <td>[comparative, analysis, main, business, proces...</td>\n",
       "      <td>6933</td>\n",
       "      <td>comparative analysis main business processes b...</td>\n",
       "      <td>Thus, the study allowed the development of a b...</td>\n",
       "      <td>para coletar os dados realizaram se entrevista...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Strategies and Best Practices for Data Literac...   \n",
       "1  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe External Effects of Bl...   \n",
       "2  \\n\\n\\nComparative analysis of the main busines...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  2012 , analysts estimated 90 world data come e...   \n",
       "1  article examines increase incarceration black ...   \n",
       "2  work aims present study business processes sma...   \n",
       "\n",
       "                                         sent_tokens  sent_tokens_counts  \\\n",
       "0  [strategies best practices data literacy educa...                2863   \n",
       "1  [external effects black male incarceration bla...                 686   \n",
       "2  [comparative analysis main business processes ...                 437   \n",
       "\n",
       "                                         word_tokens  word_tokens_counts  \\\n",
       "0  [strategies, best, practices, data, literacy, ...               48070   \n",
       "1  [external, effects, black, male, incarceration...               12116   \n",
       "2  [comparative, analysis, main, business, proces...                6933   \n",
       "\n",
       "                                     normalized_text  \\\n",
       "0  strategies best practices data literacy educat...   \n",
       "1  external effects black male incarceration blac...   \n",
       "2  comparative analysis main business processes b...   \n",
       "\n",
       "                               gensim_summarizations  \\\n",
       "0  Best practices for teaching data literacy educ...   \n",
       "1  Combining data from the Bureau of Justice Stat...   \n",
       "2  Thus, the study allowed the development of a b...   \n",
       "\n",
       "                       latent_semantic_summarization  \\\n",
       "0  found students could apply mathematical reason...   \n",
       "1  0734 306x 2011 2901 0003 10.00 1 2 mechoulan b...   \n",
       "2  para coletar os dados realizaram se entrevista...   \n",
       "\n",
       "  spacy_extraction_summarization AI_genims_scores AI_latent_scores  \\\n",
       "0                            NaN              NaN              NaN   \n",
       "1                            NaN              NaN              NaN   \n",
       "2                            NaN              NaN              NaN   \n",
       "\n",
       "  AI_frequency_scores  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_summuarization_df._buildingLatentModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Spacy Frequence Text Summarization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Words with higher frequencies:  ['data', 'literacy', 'skills']\n",
      "\n",
      "Words with higher frequencies:  ['black', 'incarceration', 'male']\n",
      "\n",
      "Words with higher frequencies:  ['business', 'process', 'processes']\n",
      "___________________spacy frequency summarized text 1:\n",
      "data literacy competencies synthesized set skills abilities together comprise various levels data literacy , present data literacy competencies matrix , organized five core aspects data literacy definition ( data , collection , management , evaluation , application ) .conceptual framework introduction data data collection data discovery collection evaluating ensuring quality data sources data management data organization data manipulation data conversion ( format format )identifying problems using data data visualization presenting data ( verbally ) data driven decisions making ( dddm ) ( making decisions based data ) data application critical thinking data culture data ethics data citation data sharing evaluating decisions basedinclude geospatial data literacy gis sector specific industry driven data literacy requirements input outside academic institutions standard assessing evaluating data literacy levels data security training students without computer science background ethics data data driven decision making provide data literacy training existing workforce addition new graduates .allows students focus specific aspects data literacy ( e.g . finding data , evaluation data , visualization , manipulation tools , data storage , data ethics , data curation , etc . ) , build competencies successively accomplish goal ( e.g . data management plan research )www.datasciencecentral.com institute nasa earth data name data discovery tools type data analysis visualization tools description part nasa earth science data systems program , earth observing system data information system ( eosdis ) provides number advanced data discovery tools used users carry search , analysis , visualization nasa earth science data .zallesessay3.pdf appendices appendix 1 data literacy competencies matrix appendix 2 data literacy definitions word cloud appendix 3 key themes data literacy literature appendix 4 annotated bibliography appendix ( 1 ( ( data ( literacy ( competencies ( matrix matrix consists key data literacy ability knowledge areas , corresponding competencies tasks required .assess data security requirements ( e.g . restricted access , protected drives , etc . ) curates data data preservation assesses requirements preservation asseses methods tools data preservation preserves data data tools knowledge data analysis tools techniques selects appropriate data analysis tool techniqueaware high level issues challlenges associated data thinks critically working data data culture recognizes importance data supports environment fosters critical use data learning , research , decision making data application data ethics aware legal ethical issues associated data applies works data ethical manner data citation knowledge widely accepted data citation methods creates correct citations secondary data sets data sharing assesses methods platforms sharing data shares data legally , ethically evaluating decisions based data collects follow data assess effectiveness decisions solutions based upon data conducts analysis follow data compares results analysis findings evaluates decisions solutions based data retains original conclusions decisions , implements new decisions solutions competency legend conceptual competencies core competencies advanced competencies authors source introduction data critical thinking data culture data ethics data tools data discovery collection data management organization data manipulation evaluating ensuring quality data sources carlson , fosmire , miller , sapp nelson (2011 carlson , johnston , westra , nichols , 2012 ) data citation basic data analysis data visualization presenting data ( verbally ) data interpratation ( understanding data ) identifying problems using data data driven decision making ( dddm ) evaluating decisions conclusions based( ) barriers effective data literacy instruction , data literacy ability understand use data effectively inform decisions , data literacy competencies skills contribution article gina schulyer julie marsh focuses data driven decision making ( dddm ) education k 12 level .doi 10.3102 0013189x12459803 theme ( ) barriers effective data literacy instruction , data literacy ability understand use data effectively inform decisions , data literacy competencies skills , delivery assessment , teach teacher contribution mandinach gummer present context trends surrounding data literacy perspective educating pre service teachers , including supportive technologies , standards , accreditation ., data literacy best taught commencement post secondary studies , delivery assessment contribution peer reviewed article focuses data management , provides reader data practitioners toolkit , applicable mainly four roles data creator , data scientist , data manager , data librarian .basis data literacy curriculum tool literacy , resource literacy , socio cultural literacy , emerging technology literacy , critical literacy eisenberg information literacy ( 2008 ) defines essential skills relate data literacy ability clarify , locate , select analyze , organize synthesize , create present , evaluate information working group information literacy defines seven pillars align data literacy identify , scope , plan , gather , evaluate , manage , present provideresearch data literacy data management competencies identify documentation ( research environmental , temporal ) context information management knowledge management scope monitoring process extracting information data models ( people ) plan data modeling metadata standards development store data analysis manipulation merging , mashing , integration protect data preservation data security access authentication conditions use data legislation evaluate data appraisal retention value data economic issues manage complaints expectation management coordination practice across institution negotiation skills risk disaster management contingency advocacy , promotion , marketing provide facilitation , communication raising awareness citation shorish , .core competencies include introduction databases data formats , discovery acquisition data , data management organization , data conversion interoperability , quality assurance , metadata , data curation reuse , cultures practice , data preservation , data analysis , data visualization , ethics ( including citations ) ( 652 653 ) .identifies appropriate data sources , also imports data converts necessary , used downstream processing tools data management organization understands lifecycle data , develops data management plans , keeps track relation subsets processed data original data sets .data relationships activity identifying data sets , class presentation share information analysis data repository dataset fundamentals data forms , scales , types , levels data structure models physical data model data activity presentations continue , quiz data database fundamentals 4.21 pp 088 093.pdf theme ( ) 21st century skills literacies , data literacy competencies skills , data literacy ability understand use data effectively inform decisions contribution paper derek mcauley et al . theorizes impact open data , big data , linked data higher education .delivery assessment , barriers effective data literacy instruction , data literacy competencies skills , 21st century skills literacies , data literacy ability understand use data effectively inform decisions contribution article michael b. twidale , catherine blake , jon gant focuses building data literacy within civil society order improve citizens engagement democratic process , understand participate data driven decision making processes .types data collected data driven marketing decision making firms include customer data , website usage data , crm data , campaign metrics , social metrics , online transactions , behavioral data , demographic data .data literacy ability understand use data effectively inform decisions , delivery assessment , barriers effective data literacy instruction contribution swan , et al. , define data literacy ability formulate answer data based questions use appropriate data , tools , representations interpret information data develop evaluate\n",
      "___________________spacy frequency summarized text 1:\n",
      "external effects black male incarceration black females ste phane mechoulan , dalhousie university article examines increase incarceration black men sex ratio imbalance induces shape behavior young black women .combining data bureau justice statistics current population survey match male incar ceration rates individual observations two decades , show black male incarceration lowers odds black non marital teenage fertility increasing young black women school attainment early employment .effects black male incarceration black females 3 policy programs versus male incarceration explaining several socio economic trends observed among american women , african amer ican women particular .examine rising levels incarceration black men lead young black women change important lifetime decisions , compiled data number male prisoners race , gender , state , year bureau justice statistics ( bjs ) .terms main fndings , models show higher rates black male incarceration signifcantly lowered odds nonmarital 4 mechoulan teenage motherhood among young black females , caveat average effect driven small number repressive states .data a. incarceration data work uniquely combines different data sets assess impact black male incarceration rates black female outcomes linking state , year , gender , race specifc male incarceration rates dividual female observations .would interesting see aggregate black male incarceration marginal impact husband race among black women june cps contain enough information spouse race run analysis .1990s.16 therefore variations total black male incarceration rates described satisfactory estimate variations black young adult male incarceration rates .probability effects black male incarceration black females 13 said , effect aggregate african american male incar ceration female outcomes principle decomposedincrease black female incarceration , however , relatively small.19 would ideal disentangle frst order , indirect effects male carceration second order , direct effects female incarceration female outcomes .100,000 black males period breakdown age groups un available females 1997 2000 83 incarcerated black women per 100,000 18 19 age range , opposed 2,679 black men ( according bjs prisonersyet , factors affect incarceration may also vary within state time simply controlling year state effects could still bias estimation incarceration coeffcients.21 address problem , specifcations made fexible adding inter action terms state effects time trend state effects square time trend ( see , e.g. , friedberg 1998 ) .effects black male incarceration black females 15 jumps incarceration rates would providenotwithstanding diffculty , use linear probability models successively control year effects , state effects , state linear quadratic time trends.23 black box nature ap proach , try characterize main variables poten tially correlated incarceration outcomes interest state level trends absorb .interpretation coeffcients becomes impact male incarceration average young black woman united states , opposed average effect black male incarceration across states .ef fect assign white male incarceration rate white females black male incarceration rate black females run regressions groups .effects black male incarceration black females 19 purged local effects previously picked , extent change slowly time , well captured trend terms.27 dropping different regions coded circuit court time model 3 , results hold except removing circuit court 5.looking black white comparison , interaction coeffcient black incarceration rate model 9 shows response male incarceration group , black females reduce fertility relative white females , signifcantly 10 level .white population age range , effect measured race specifc incarceration coeffcient small insignifcant.31 using parameterization model 3 , also regressed black teenage fertility white male incarceration rates effect found negative , large magnitude , statistically insignifcant.32 finally , also estimated model time links birth outcomes incarceration rates narrowly .finally , june cps confrms married black women respond incarceration single women also reveals young black married mothers signifcantly contribute increase full time em ployment among young black women general .particular , black male incarceration decreases early black nonmarital fertility increases black female education early employment .study effects massive male incarceration women outcomes , case tectonic economics , infancy.47 example , johnson raphael ( 2005 ) advance higher prevalence hiv among black women connected black male incarceration rates .\n",
      "___________________spacy frequency summarized text 1:\n",
      "based information obtained , business process modeling developed using bpmn notation ( business process modeling notation ) .keywords business processes process mapping basic model business processes subsector buildings .according hola ( 2015 ) , recent research shows civil engineers responsible micro small construction companies , since professionals extensive knowledge area project design construction site , however , less knowledge business management business process management .hand , literature discusses interest business process management construction companies , knowledge process approach advantages applying best practices still negligible ( hola et al. , 2012 ) .identification representation common business processes companies studied carried bpmn notation ( business process modeling notation ) , one methods used know detail depth operations occur within organizations .development research observed actually happens construction environment day day , good way find manage business processes , firstly , necessary visualize end end document , able define work patterns , avoid redundant processes , even design new processes .thus , model process mappings , relevant practical examples , contained study , besides motivate interest building companies , also induce industries perform modeling conceptualize processes know sequence work activities , thus creating business process architecture .process model provide comprehensive overview process , allowing organization analyzed integrated sets processes , given importance correctly modeling business processes , transforming formal representations ( aguilar sav n ,song choi ( 2011 ) suggested sustainable business process management model ( sbpm ) , allows continuous improvement business processes companies civil construction sector .sustainable business process management model ( sbpm ) visualizes business process , establishes human resources , relates systems tasks process oriented way .bpmn language ( business process modeling notation ) used represent process modeling , using bizagi software , describe graphical environment business processes agile simple way .3.1 notation software business process modeling according cardoso aalst ( 2009 ) , pavani scucuglia ( 2011 ) , valle oliveira ( 2009 ) , among notations , design processes , known today used workflow languages bpmn process modeling notation , uml activity diagrams , business process execution language ( bpel ) , idef 0 ( integration definition methods 0 ) , epc ( event process chain )2004 , bpmi ( business process management initiative ) , non governmental organization , created version 1.0 bpmn ( business process modeling notation ) .purpose , bpmi ( business process management initiative ) support main information technology companies world ( international business machines , management information systems , oracle , microsoft , rational , among others ) .bpmn notation technique ( business process modeling notation ) specific business process modeling , since existence evaluated academic community widely supported researchers ( brocke rosemann , 2010a cardoso aalst , 2009 ) .companies internally carry processes prospecting new constructions business , coordination planning projects , preparation analysis budget , process purchase materials services , sales marketing , financial management , human resources ( hr ) management , management construction site .business processes project coordination planning , commercialization buildings , budget preparation analysis , acquisition materials services , execution constructions , sales services , management outsourced services , health management , environment work safety prospecting new buildings typical small companies sub sector buildings .6 conclusions bibliographical researches , direct contact builders also analysis results obtained , possible achieve objective studying business processes small companies subsector buildings , aiming develop basic model processes companies sector .front informations collected , based interviews conducted companies participating research , basic model summarizes main business processes ( 1 ) develop vision strategy , ( 2 ) coordinate plan projects , ( 3 ) elaborate analyze budget , ( 4 ) sell buildings , ( 5 ) acquiring materials services , ( 6 ) execute manage construction site ,transmitted method research process learning , therefore study shares procedures learned theory practice business process mapping , basic model created transmit information , removing construction managers vision individual processes .detail process planning control construction sites , identifying problems occur terms time activity mappings research use bpm practices ( business process management ) , , apply continuous life cycle bpm activities .process modeling bpmn language ( business process modeling notation ) used represent process modeling , using bizagi software , describe graphical environment business processes agile simple way .\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>abstract</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>sent_tokens_counts</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>word_tokens_counts</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>gensim_summarizations</th>\n",
       "      <th>latent_semantic_summarization</th>\n",
       "      <th>spacy_extraction_summarization</th>\n",
       "      <th>AI_genims_scores</th>\n",
       "      <th>AI_latent_scores</th>\n",
       "      <th>AI_frequency_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Strategies and Best Practices for Data Literac...</td>\n",
       "      <td>2012 , analysts estimated 90 world data come e...</td>\n",
       "      <td>[strategies best practices data literacy educa...</td>\n",
       "      <td>2863</td>\n",
       "      <td>[strategies, best, practices, data, literacy, ...</td>\n",
       "      <td>48070</td>\n",
       "      <td>strategies best practices data literacy educat...</td>\n",
       "      <td>Best practices for teaching data literacy educ...</td>\n",
       "      <td>found students could apply mathematical reason...</td>\n",
       "      <td>data literacy competencies synthesized set ski...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe External Effects of Bl...</td>\n",
       "      <td>article examines increase incarceration black ...</td>\n",
       "      <td>[external effects black male incarceration bla...</td>\n",
       "      <td>686</td>\n",
       "      <td>[external, effects, black, male, incarceration...</td>\n",
       "      <td>12116</td>\n",
       "      <td>external effects black male incarceration blac...</td>\n",
       "      <td>Combining data from the Bureau of Justice Stat...</td>\n",
       "      <td>0734 306x 2011 2901 0003 10.00 1 2 mechoulan b...</td>\n",
       "      <td>external effects black male incarceration blac...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\nComparative analysis of the main busines...</td>\n",
       "      <td>work aims present study business processes sma...</td>\n",
       "      <td>[comparative analysis main business processes ...</td>\n",
       "      <td>437</td>\n",
       "      <td>[comparative, analysis, main, business, proces...</td>\n",
       "      <td>6933</td>\n",
       "      <td>comparative analysis main business processes b...</td>\n",
       "      <td>Thus, the study allowed the development of a b...</td>\n",
       "      <td>para coletar os dados realizaram se entrevista...</td>\n",
       "      <td>based information obtained , business process ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Strategies and Best Practices for Data Literac...   \n",
       "1  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe External Effects of Bl...   \n",
       "2  \\n\\n\\nComparative analysis of the main busines...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  2012 , analysts estimated 90 world data come e...   \n",
       "1  article examines increase incarceration black ...   \n",
       "2  work aims present study business processes sma...   \n",
       "\n",
       "                                         sent_tokens  sent_tokens_counts  \\\n",
       "0  [strategies best practices data literacy educa...                2863   \n",
       "1  [external effects black male incarceration bla...                 686   \n",
       "2  [comparative analysis main business processes ...                 437   \n",
       "\n",
       "                                         word_tokens  word_tokens_counts  \\\n",
       "0  [strategies, best, practices, data, literacy, ...               48070   \n",
       "1  [external, effects, black, male, incarceration...               12116   \n",
       "2  [comparative, analysis, main, business, proces...                6933   \n",
       "\n",
       "                                     normalized_text  \\\n",
       "0  strategies best practices data literacy educat...   \n",
       "1  external effects black male incarceration blac...   \n",
       "2  comparative analysis main business processes b...   \n",
       "\n",
       "                               gensim_summarizations  \\\n",
       "0  Best practices for teaching data literacy educ...   \n",
       "1  Combining data from the Bureau of Justice Stat...   \n",
       "2  Thus, the study allowed the development of a b...   \n",
       "\n",
       "                       latent_semantic_summarization  \\\n",
       "0  found students could apply mathematical reason...   \n",
       "1  0734 306x 2011 2901 0003 10.00 1 2 mechoulan b...   \n",
       "2  para coletar os dados realizaram se entrevista...   \n",
       "\n",
       "                      spacy_extraction_summarization AI_genims_scores  \\\n",
       "0  data literacy competencies synthesized set ski...              NaN   \n",
       "1  external effects black male incarceration blac...              NaN   \n",
       "2  based information obtained , business process ...              NaN   \n",
       "\n",
       "  AI_latent_scores AI_frequency_scores  \n",
       "0              NaN                 NaN  \n",
       "1              NaN                 NaN  \n",
       "2              NaN                 NaN  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_summuarization_df._buildingSpacyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8: Comparsion among three models\n",
    "##### Measure the models based on nltk.cluster.util.cosine_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________AI_genims_scores:\n",
      "[0.12917041325966727, 0.3094812038209358, 0.1578590072684921]\n",
      "___________________AI_latent_scores:\n",
      "[0.7171771877657815, 0.3153025202449947, 0.6025933060834799]\n",
      "___________________AI_frequency_scores:\n",
      "[0.7906782380201131, 0.6164103653790518, 0.7018493474521429]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>abstract</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>sent_tokens_counts</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>word_tokens_counts</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>gensim_summarizations</th>\n",
       "      <th>latent_semantic_summarization</th>\n",
       "      <th>spacy_extraction_summarization</th>\n",
       "      <th>AI_genims_scores</th>\n",
       "      <th>AI_latent_scores</th>\n",
       "      <th>AI_frequency_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Strategies and Best Practices for Data Literac...</td>\n",
       "      <td>2012 , analysts estimated 90 world data come e...</td>\n",
       "      <td>[strategies best practices data literacy educa...</td>\n",
       "      <td>2863</td>\n",
       "      <td>[strategies, best, practices, data, literacy, ...</td>\n",
       "      <td>48070</td>\n",
       "      <td>strategies best practices data literacy educat...</td>\n",
       "      <td>Best practices for teaching data literacy educ...</td>\n",
       "      <td>found students could apply mathematical reason...</td>\n",
       "      <td>data literacy competencies synthesized set ski...</td>\n",
       "      <td>0.129170</td>\n",
       "      <td>0.717177</td>\n",
       "      <td>0.790678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe External Effects of Bl...</td>\n",
       "      <td>article examines increase incarceration black ...</td>\n",
       "      <td>[external effects black male incarceration bla...</td>\n",
       "      <td>686</td>\n",
       "      <td>[external, effects, black, male, incarceration...</td>\n",
       "      <td>12116</td>\n",
       "      <td>external effects black male incarceration blac...</td>\n",
       "      <td>Combining data from the Bureau of Justice Stat...</td>\n",
       "      <td>0734 306x 2011 2901 0003 10.00 1 2 mechoulan b...</td>\n",
       "      <td>external effects black male incarceration blac...</td>\n",
       "      <td>0.309481</td>\n",
       "      <td>0.315303</td>\n",
       "      <td>0.616410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\nComparative analysis of the main busines...</td>\n",
       "      <td>work aims present study business processes sma...</td>\n",
       "      <td>[comparative analysis main business processes ...</td>\n",
       "      <td>437</td>\n",
       "      <td>[comparative, analysis, main, business, proces...</td>\n",
       "      <td>6933</td>\n",
       "      <td>comparative analysis main business processes b...</td>\n",
       "      <td>Thus, the study allowed the development of a b...</td>\n",
       "      <td>para coletar os dados realizaram se entrevista...</td>\n",
       "      <td>based information obtained , business process ...</td>\n",
       "      <td>0.157859</td>\n",
       "      <td>0.602593</td>\n",
       "      <td>0.701849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Strategies and Best Practices for Data Literac...   \n",
       "1  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe External Effects of Bl...   \n",
       "2  \\n\\n\\nComparative analysis of the main busines...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  2012 , analysts estimated 90 world data come e...   \n",
       "1  article examines increase incarceration black ...   \n",
       "2  work aims present study business processes sma...   \n",
       "\n",
       "                                         sent_tokens  sent_tokens_counts  \\\n",
       "0  [strategies best practices data literacy educa...                2863   \n",
       "1  [external effects black male incarceration bla...                 686   \n",
       "2  [comparative analysis main business processes ...                 437   \n",
       "\n",
       "                                         word_tokens  word_tokens_counts  \\\n",
       "0  [strategies, best, practices, data, literacy, ...               48070   \n",
       "1  [external, effects, black, male, incarceration...               12116   \n",
       "2  [comparative, analysis, main, business, proces...                6933   \n",
       "\n",
       "                                     normalized_text  \\\n",
       "0  strategies best practices data literacy educat...   \n",
       "1  external effects black male incarceration blac...   \n",
       "2  comparative analysis main business processes b...   \n",
       "\n",
       "                               gensim_summarizations  \\\n",
       "0  Best practices for teaching data literacy educ...   \n",
       "1  Combining data from the Bureau of Justice Stat...   \n",
       "2  Thus, the study allowed the development of a b...   \n",
       "\n",
       "                       latent_semantic_summarization  \\\n",
       "0  found students could apply mathematical reason...   \n",
       "1  0734 306x 2011 2901 0003 10.00 1 2 mechoulan b...   \n",
       "2  para coletar os dados realizaram se entrevista...   \n",
       "\n",
       "                      spacy_extraction_summarization  AI_genims_scores  \\\n",
       "0  data literacy competencies synthesized set ski...          0.129170   \n",
       "1  external effects black male incarceration blac...          0.309481   \n",
       "2  based information obtained , business process ...          0.157859   \n",
       "\n",
       "   AI_latent_scores  AI_frequency_scores  \n",
       "0          0.717177             0.790678  \n",
       "1          0.315303             0.616410  \n",
       "2          0.602593             0.701849  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_summuarization_df._modelComparsion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy Frequency Summarization seems to give the best results based on NLTK COSINE metric. Next, I want to statistically caluclate COSINE results based on forumla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9: Summary: Select the best model based on the enduser sepecified above\n",
    "##### Statistically measure three models again by the forumla: ((tfidf * tfidf.T).A)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________AI_genims_scores_avg:\n",
      "0.2573857657097694\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________AI_latent_scores_avg:\n",
      "0.298471887072291\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________AI_frequency_scores_avg:\n",
      "0.6096851148311403\n",
      "___________________The best score:\n",
      "0.6096851148311403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_summuarization_df._selectBestModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, Spacy Frequency Summarization gives the best results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: general guildline for Enduser\n",
    "#### Based on the experience of this research, we are proposing the guideline for the end-user is as following: \n",
    "##### Step 1: Identify whether authors provide their abstract summarization or create human-made summarization text with the help of experts in the same business domain.\n",
    "##### Step 2: Normalized the original text with recommended filters, such as stopwords, puncturations, HTML tags, and special characters if necessary.\n",
    "##### Step 3: For some rare cases, the meager frequent words might have to filter out during the text preprocessing process.\n",
    "##### Step 4: Consider the parameters for text summarization. Such as summarization ratio, word counts limits. The necessary calculation might need to kick in at the step.\n",
    "##### Step 5: Prepare at least two models with different approaches based on the A/B evaluation concept. In our case, we choose Gensim, Latent, and Spacy for the modeling. \n",
    "##### Step 6: Select at least two metrics to ensure the comparison results among the models are consistent. In our case, we choose NLTK cosine distance and TFID Vector for measurement.\n",
    "##### Step 7: Compare the results of the models and generate a statistical report. Visualization might be needed for complex system comparison.\n",
    "##### Step 8: Choose the best model based on step 7.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
